<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://kololantoo.github.io</id>
    <title>Gridea</title>
    <updated>2022-07-15T08:16:56.579Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://kololantoo.github.io"/>
    <link rel="self" href="https://kololantoo.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://kololantoo.github.io/images/avatar.png</logo>
    <icon>https://kololantoo.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[ElasticSearch安装和基于Springboot使用]]></title>
        <id>https://kololantoo.github.io/post/elasticsearch-an-zhuang-he-ji-yu-springboot-shi-yong/</id>
        <link href="https://kololantoo.github.io/post/elasticsearch-an-zhuang-he-ji-yu-springboot-shi-yong/">
        </link>
        <updated>2022-07-15T08:15:15.000Z</updated>
        <content type="html"><![CDATA[<h2 id="安装">安装</h2>
<h3 id="1-下载安装包">1. 下载安装包</h3>
<p>打开 https://www.elastic.co/cn/downloads/elasticsearch 官网，选择对应平台的安装包进行下载</p>
<figure data-type="image" tabindex="1"><img src="https://cdn.jsdelivr.net/gh/kololantoo/ImageHost@master/blog/202207131005014.png" alt="image-20220713100537881" loading="lazy"></figure>
<h3 id="2解压缩下载的安装包">2.解压缩下载的安装包</h3>
<pre><code class="language-shell">tar -zxvf ./elasticsearch-7.8.0-linux-x86_64.tar.gz -C /usr/local
</code></pre>
<h3 id="3创建esuser用户">3.创建esuser用户</h3>
<p>因为 elasticsearch 不能使用 root 用户启动，因此需要另行添加一个用户，用于启动elasticsearch</p>
<pre><code class="language-shell">adduser esuser
</code></pre>
<h3 id="4修改elasticsearch安装目录的用户">4.修改elasticsearch安装目录的用户</h3>
<pre><code class="language-shell">chown -R esuser:esuser /usr/local/elasticsearch
</code></pre>
<h3 id="5服务器配置修改">5.服务器配置修改</h3>
<p>由于 Linux 系统对非root用户限制了打开的线程数及打开的文件描述符数量，因此要对这部分配置进行修改</p>
<p><strong>修改/etc/security/limits.conf</strong></p>
<p>在文件末尾，添加如下内容</p>
<pre><code class="language-shell">esuser hard nofile 65536
esuser soft nofile 65536
esuser soft nproc 4096
esuser hard nproc 4096
</code></pre>
<p><strong>修改/etc/sysctl.conf</strong></p>
<p>在文件末尾添加如下内容</p>
<pre><code class="language-shell">vm.max_map_count=262144
</code></pre>
<p>然后执行命令，使修改立即生效</p>
<pre><code class="language-shell">sysctl -p 
</code></pre>
<p>使用如下命令，查看上述两项修改后的结果</p>
<pre><code class="language-shell">ulimit -a
sysctl -a | grep vm.max_map_count
</code></pre>
<h3 id="6开放端口">6.开放端口</h3>
<pre><code class="language-shell"># 查看当前开放的端口
firewall-cmd --list-all
# 设置开放端口号
firewall-cmd --add-port=9100/tcp --permanent
firewall-cmd --add-port=9200/tcp --permanent
firewall-cmd --add-port=9300/tcp --permanent
# 重启防火墙
firewall-cmd --reload
</code></pre>
<p>上述三个端口，将分别用于es head，es http访问，es集群内部节点通信，因此都需要打开</p>
<h3 id="7修改elasticsearchyml配置">7.修改elasticsearch.yml配置</h3>
<p>由于这里部署的是一个 elasticsearch 集群，在完成上述配置之后，需在集群部署的服务器上，修改各自的elasticsearch.yml配置文件。</p>
<p>打开到 /usr/local/elasticsearch/config 目录，修改 elasticsearch.yml 文件。</p>
<p>我这里部署的是一个双节点集群，两个节点的 elasticsearch.yml 文件如下</p>
<h4 id="节点1"><strong>节点1</strong></h4>
<pre><code class="language-yaml">cluster.name: elasticsearch
node.name: es-node0
path.data: /home/elasticsearch/data
path.logs: /home/elasticsearch/logs
bootstrap.memory_lock: false
bootstrap.system_call_filter: false
network.host: 0.0.0.0
http.port: 9200
http.cors.enabled: true
http.cors.allow-origin: &quot;*&quot;
discovery.seed_hosts: [&quot;10.10.181.26&quot;, &quot;10.10.181.27&quot;]
cluster.initial_master_nodes: [&quot;es-node0&quot;,&quot;es-node1&quot;]
node.master: true
node.data: true
xpack.security.enabled: false
</code></pre>
<h4 id="节点2"><strong>节点2</strong></h4>
<pre><code class="language-yaml">cluster.name: elasticsearch
node.name: es-node1
path.data: /home/elasticsearch/data
path.logs: /home/elasticsearch/logs
bootstrap.memory_lock: false
bootstrap.system_call_filter: false
network.host: 0.0.0.0
http.port: 9200
http.cors.enabled: true
http.cors.allow-origin: &quot;*&quot;
discovery.seed_hosts: [&quot;10.10.181.26&quot;, &quot;10.10.181.27&quot;]
cluster.initial_master_nodes: [&quot;es-node0&quot;,&quot;es-node1&quot;]
node.master: true
node.data: true
xpack.security.enabled: false
</code></pre>
<h3 id="8启动elasticsearch">8.启动elasticsearch</h3>
<p>在两台服务器上，切换到 esuser 用户，打开到安装目录的 bin 文件夹，执行启动命令</p>
<pre><code class="language-shell">su esuser
cd /usr/local/elasticsearch/bin
./elasticsearch -d
# 关闭es 命令
ps -ef|grep elasticsearch
kill -9 进程号
</code></pre>
<p><strong>注意：如果不小心以 root 用户启动了elasticsearch，需要先删除 /home/elasticsearch/data和/home/elasticsearch/logs这两个目录，然后切换至esuser用户，再重新尝试启动</strong></p>
<h3 id="9查看安装情况">9.查看安装情况</h3>
<p>查看安装情况</p>
<p>http://localhost:9200/</p>
<p><strong>查看es安装的插件</strong></p>
<p>http://localhost:9200/_cat/plugins</p>
<p><strong>查看集群节点状态</strong></p>
<p>http://localhost:9200/_cat/nodes?pretty</p>
<p><strong>查看所有索引</strong></p>
<p>http://localhost:9200/_cat/indices?v</p>
<p><strong>查看集群健康状态</strong></p>
<p>http://localhost:9200/_cat/health</p>
<p><strong>查看当前主节点</strong></p>
<p>http://localhost:9200/_cat/master</p>
<h3 id="10-安装分词器命令">10. 安装分词器命令</h3>
<p>打开到 bin 目录，执行如下命令，将版本替换为自己安装的es版本号即可</p>
<pre><code class="language-shell">su esuser
cd /usr/local/elasticsearch/bin
./elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.9.0/elasticsearch-analysis-ik-7.9.0.zip

 ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-pinyin/releases/download/v7.9.0/elasticsearch-analysis-pinyin-7.9.0.zip
</code></pre>
<h3 id="11-其他elasticsearchyml重要配置">11. 其他elasticsearch.yml重要配置</h3>
<pre><code class="language-yaml">#配置 ES 的集群名称，默认值是 ES，建议改成与所存数据相关的名称，ES 会自动发现在同一网段下的集群名称相同的节点。
cluster.name：elasticsearch

#集群中的节点名，在同一个集群中不能重复。节点的名称一旦设置，就不能再改变了。当然，也可以设置成服务器的主机名称，例如 node.name:${HOSTNAME}。
node.nam： &quot;node1&quot;

#指定该节点是否有资格被选举成为 Master 节点，默认是 True，如果被设置为 True，则只是有资格成为 Master 节点，具体能否成为 Master 节点，需要通过选举产生。
noed.master：true

#指定该节点是否存储索引数据，默认为 True。数据的增、删、改、查都是在 Data 节点完成的。
node.data：true

#设置都索引分片个数，默认是 5 片。也可以在创建索引时设置该值，具体设置为多大都值要根据数据量的大小来定。如果数据量不大，则设置成 1 时效率最高。
index.number_of_shards：5

#设置默认的索引副本个数，默认为 1 个。副本数越多，集群的可用性越好，但是写索引时需要同步的数据越多。
index.number_of_replicas：1

#设置配置文件的存储路径，默认是 ES 目录下的 Conf 文件夹。建议使用默认值。
path.conf：/path/to/conf

#设置索引数据多存储路径，默认是 ES 根目录下的 Data 文件夹。切记不要使用默认值，因为若 ES 进行了升级，则有可能数据全部丢失。 可以用半角逗号隔开设置的多个存储路径，在多硬盘的服务器上设置多个存储路径是很有必要的。
path.data：/path/to/data1,/path/to/data2

#设置日志文件的存储路径，默认是 ES 根目录下的 Logs，建议修改到其他地方。
path.logs：/path/to/logs

#设置第三方插件的存放路径，默认是 ES 根目录下的 Plugins 文件夹。
path.plugins：/path/to/plugins

#设置为 True 时可锁住内存。因为当 JVM 开始 Swap 时，ES 的效率会降低，所以要保证它不 Swap。
bootstrap.mlockall：true

#设置本节点绑定的 IP 地址，IP 地址类型是 IPv4 或 IPv6，默认为 0.0.0.0。
network.bind_host：192.168.0.1

#设置其他节点和该节点交互的 IP 地址，如果不设置，则会进行自我判断。
network.publish_host：192.168.0.1

#用于同时设置 bind_host 和 publish_host 这两个参数。
network.host：192.168.0.1

#设置对外服务的 HTTP 端口，默认为 9200。ES 的节点需要配置两个端口号，一个对外提供服务的端口号，一个是集群内部使用的端口号。 http.port 设置的是对外提供服务的端口号。注意，如果在一个服务器上配置多个节点，则切记对端口号进行区分。
http.port：9200

#设置集群内部的节点间交互的 TCP 端口，默认是 9300。注意，如果在一个服务器配置多个节点，则切记对端口号进行区分。
transport.tcp.port：9300

#设置在节点间传输数据时是否压缩，默认为 False，不压缩。
transport.tcp.compress：true

#设置在选举 Master 节点时需要参与的最少的候选主节点数，默认为 1。如果使用默认值，则当网络不稳定时有可能会出现脑裂。 合理的数值为(master_eligible_nodes/2)+1，其中 master_eligible_nodes 表示集群中的候选主节点数。
discovery.zen.minimum_master_nodes：1

#设置在集群中自动发现其他节点时 Ping 连接的超时时间，默认为 3 秒。 在较差的网络环境下需要设置得大一点，防止因误判该节点的存活状态而导致分片的转移。
discovery.zen.ping.timeout：3s
</code></pre>
<h2 id="基于springboot使用">基于Springboot使用</h2>
<h3 id="1-引入依赖">1. 引入依赖</h3>
<pre><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
  &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="2配置-elasticsearch-集群地址">2.配置 elasticsearch 集群地址</h3>
<pre><code class="language-properties">spring.elasticsearch.uris=http://10.10.181.26:9200,http://10.10.181.27:9200
</code></pre>
<h3 id="3创建索引实体类">3.创建索引实体类</h3>
<pre><code class="language-java">@Document(indexName = &quot;demo&quot;)
@Setting(replicas = 2,shards = 2)
@Data
public class MyEsDemo {

    /**
     * 测试使用id查询的相关语句
     */
    @Id
    @Field(type = FieldType.Long)
    private Long id;

    /**
     * 简单的text类型
     */
    @Field(type = FieldType.Text)
    private String normalText1;

    /**
     * 简单的text类型
     */
    @Field(type = FieldType.Text)
    private String normalText2;

    /**
     * 将normalText1和normalText2组合起来
     */
    @Field(type = FieldType.Text)
    private String combineText;

    /**
     * 简单的keyword类型
     */
    @Field(type = FieldType.Keyword)
    private String normalKeyword;

    /**
     * 既建索引时用 ik_max_word 尽可能多的分词，而搜索时用 ik_smart 尽可能提高匹配准度，让用户的搜索尽可能的准确
     */
    @Field(type = FieldType.Text,analyzer = &quot;ik_max_word&quot;,searchAnalyzer = &quot;ik_smart&quot;)
    private String analyzeText;

    /**
     * 指定日期格式
     */
    @Field(type = FieldType.Date, format = DateFormat.date_hour_minute_second)
    private Date date;

    /**
     * Boolean类型的值
     */
    @Field(type = FieldType.Boolean)
    private Boolean boolVal;

    /**
     * Double 类型的值
     */
    @Field(type = FieldType.Double)
    private Double doubleVal;

    /**
     * List 类型的值
     */
    @Field(type = FieldType.Text)
    private List&lt;String&gt; list;
}
</code></pre>
<h3 id="4-基础crud">4. 基础CRUD</h3>
<h4 id="1新增"><strong>1.新增</strong></h4>
<pre><code class="language-java">@Service
// 使用lombok此注解之后，Autowired 的对象必须是final或者是@NotNull
@RequiredArgsConstructor(onConstructor = @__(@Autowired))
@Slf4j
public class AddService {

    @Autowired
    private final ElasticsearchRestTemplate template;
    @Autowired
    private final MyEsDemoRepository repository;
    @Autowired
    private final RestHighLevelClient client;
    @Autowired
    private final SnowflakeIdUtil snowflakeIdUtil;

    /**
     * 使用ElasticsearchRestTemplate新增
     * @param demo
     */
    public void addByTemplate(MyEsDemo demo) {
        template.setRefreshPolicy(RefreshPolicy.IMMEDIATE);
        template.save(demo);
    }

    /**
     * 使用ElasticsearchRestTemplate批量新增
     * @param list
     */
    public void addBatchByTemplate(List&lt;MyEsDemo&gt; list) {
        template.setRefreshPolicy(RefreshPolicy.IMMEDIATE);
        template.save(list);
    }

    /**
     * 使用Repository新增
     * @param demo
     */
    public void addByRepository(MyEsDemo demo) {
        repository.save(demo);
    }

    /**
     * 使用Repository批量新增
     * @param list
     */
    public void addBatchByRepository(List&lt;MyEsDemo&gt; list) {
        repository.saveAll(list);
    }

    /**
     * 使用RestClient新增
     * @param demo
     */
    public void addByRestClient(MyEsDemo demo) {
        String indexName = demo.getClass().getAnnotation(Document.class).indexName();
        IndexRequest indexRequest = new IndexRequest(indexName);

        indexRequest.id(String.valueOf(snowflakeIdUtil.nextId()));
        indexRequest.source(JSON.toJSONString(demo), XContentType.JSON);

        try {
            client.index(indexRequest, RequestOptions.DEFAULT);
        } catch (IOException e) {
            log.error(&quot;保存失败&quot;);
        }
    }

    /**
     * 使用RestClient批量新增
     * @param list
     */
    public void addBatchByRestClient(List&lt;MyEsDemo&gt; list) {
        if (CollectionUtils.isEmpty(list)) {
            return;
        }
        String indexName = list.get(0).getClass().getAnnotation(Document.class).indexName();

        BulkRequest request = new BulkRequest();
        for (MyEsDemo demo : list) {
            request.add(new IndexRequest(indexName)
                    .id(String.valueOf(snowflakeIdUtil.nextId()))
                    .source(JSONObject.toJSONString(demo), XContentType.JSON)
            );
        }

        try {
            client.bulk(request,RequestOptions.DEFAULT);
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }
}
</code></pre>
<h4 id="2删除"><strong>2.删除</strong></h4>
<pre><code class="language-java">@Service
@RequiredArgsConstructor(onConstructor = @__(@Autowired))
@Slf4j
public class DeleteService {


    @Autowired
    private final ElasticsearchRestTemplate template;
    @Autowired
    private final MyEsDemoRepository repository;
    @Autowired
    private final RestHighLevelClient client;

    /**
     * 使用Template删除
     * @param demo
     */
    public void deleteByTemplate(MyEsDemo demo) {
        template.setRefreshPolicy(RefreshPolicy.IMMEDIATE);
        template.delete(demo);
    }

    /**
     * 使用Template批量删除
     * @param list
     */
    public void deleteBatchByTemplate(List&lt;MyEsDemo&gt; list) {
        template.setRefreshPolicy(RefreshPolicy.IMMEDIATE);
        for (MyEsDemo demo : list) {
            template.delete(demo);
        }
    }

    /**
     * 使用Template根据查询条件删除
     */
    public void queryDeleteByTemplate() {
        NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder();
        builder.withQuery(QueryBuilders.matchQuery(&quot;id&quot;,1));
        template.delete(builder.build(), MyEsDemo.class);
    }

    /**
     * 使用Repository删除
     * @param demo
     */
    public void deleteByRepository(MyEsDemo demo) {
        repository.deleteById(demo.getId());
    }

    /**
     * 使用Repository批量删除
     * @param list
     */
    public void deleteBatchByRepository(List&lt;MyEsDemo&gt; list) {
        List&lt;Long&gt; idList = list.stream().map(MyEsDemo::getId).collect(Collectors.toList());
        repository.deleteAllById(idList);
    }

    /**
     * 使用RestClient删除
     * @param demo
     * @throws IOException
     */
    public void deleteByRestClient(MyEsDemo demo) throws IOException {
        String indexName = demo.getClass().getAnnotation(Document.class).indexName();
        DeleteRequest deleteRequest = new DeleteRequest(indexName, String.valueOf(demo.getId()));
        client.delete(deleteRequest, RequestOptions.DEFAULT);
    }

    /**
     * 使用RestClient批量删除
     * @param list
     * @throws IOException
     */
    public void deleteBatchByRestClient(List&lt;MyEsDemo&gt; list) throws IOException {
        BulkRequest bulkRequest = new BulkRequest();
        list.forEach(e-&gt;{
            DeleteRequest deleteRequest = new DeleteRequest(&quot;demo&quot;, String.valueOf(e.getId()));
            bulkRequest.add(deleteRequest);
        });
        client.bulk(bulkRequest,RequestOptions.DEFAULT);
    }

    /**
     * 使用RestClient条件查询删除
     * @throws IOException
     */
    public void queryDeleteByRestClient() throws IOException {
        DeleteByQueryRequest request = new DeleteByQueryRequest(&quot;sub_bank1031&quot;);
        request.setQuery(QueryBuilders.matchQuery(&quot;id&quot;,1));
        client.deleteByQuery(request, RequestOptions.DEFAULT);
    }

}
</code></pre>
<h4 id="3修改"><strong>3.修改</strong></h4>
<pre><code class="language-java">@Service
@RequiredArgsConstructor(onConstructor = @__(@Autowired))
@Slf4j
public class UpdateService {

    @Autowired
    private final ElasticsearchRestTemplate template;
    @Autowired
    private final RestHighLevelClient client;

    /**
     * 使用Template的save方法进行更新，该方法会覆盖会将id相等数据的所有字段均替换为新传入对象的字段值，null也会覆盖，若id不匹配，则新增
     * @param demo
     */
    public void updateByTemplateSave(MyEsDemo demo) {
        template.save(demo);
    }

    /**
     * 使用Template进行update，注意withDocAsUpsert属性
     * @param demo
     */
    public void updateByTemplate(MyEsDemo demo) {
        Document document = Document.create();
        document.fromJson(JSON.toJSONString(demo));
        UpdateQuery query = UpdateQuery
                .builder(String.valueOf(demo.getId()))
                .withDocument(document)
                // 文档不存在时插入
                .withDocAsUpsert(true)
                .build();
        template.update(query, IndexCoordinates.of(&quot;demo&quot;));
    }

    /**
     * 使用Template进行批量更新
     * @param list
     */
    public void updateBatchByTemplate(List&lt;MyEsDemo&gt; list) {
        List&lt;UpdateQuery&gt; updateQueryList = new ArrayList&lt;&gt;();
        for (MyEsDemo demo : list) {
            Document document = Document.create();
            document.fromJson(JSON.toJSONString(demo));
            UpdateQuery query = UpdateQuery
                    .builder(String.valueOf(demo.getId()))
                    .withDocument(document)
                    // 文档不存在时插入
                    .withDocAsUpsert(true)
                    .build();
            updateQueryList.add(query);
        }
        template.bulkUpdate(updateQueryList,MyEsDemo.class);
    }

    /**
     * 使用Template进行条件查询更新，该方法将是的查询到的对象中，Document中指定的字段都被更新为对应值
     */
    public void queryUpdateByTemplate() {
        NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder();
        queryBuilder.withQuery(QueryBuilders.matchQuery(&quot;id&quot;,1));
        Document document = Document.create();
        document.put(&quot;normalText1&quot;,&quot;使用esTemplate进行条件查询更新&quot;);
        // 条件更新，将其normalText1字段进行更新
        UpdateQuery query = UpdateQuery
                .builder(queryBuilder.build())
                .withDocument(document)
                .build();
        template.updateByQuery(query,IndexCoordinates.of(&quot;demo&quot;));
    }


    /**
     * 使用RestClient进行更新
     * @param demo
     * @throws IOException
     */
    public void updateByRestClient(MyEsDemo demo) throws IOException {
        UpdateRequest updateRequest = new UpdateRequest(&quot;demo&quot;, String.valueOf(demo.getId()));
        Document document = Document.create();
        document.fromJson(JSON.toJSONString(demo));
        updateRequest.doc(document);
        client.update(updateRequest, RequestOptions.DEFAULT);
    }

    /**
     * 使用RestClient进行批量更新
     * @param list
     * @throws IOException
     */
    public void batchUpdateByRestClient(List&lt;MyEsDemo&gt; list) throws IOException {
        BulkRequest bulkRequest = new BulkRequest();
        list.forEach(e-&gt;{
            //获取id
            UpdateRequest updateRequest = new UpdateRequest();
            updateRequest.index(&quot;demo&quot;);
            // true，表明如果文档不存在，则新更新的文档内容作为新的内容插入文档，这个和scriptedUpsert的区别是：更新文档的两种不同方式，有的使用doc方法更新有的使用脚本更新
            updateRequest.docAsUpsert(true);
            //更新的id
            updateRequest.id(String.valueOf(e.getId()));
            //更新的数据
            Document document = Document.create();
            document.fromJson(JSON.toJSONString(e));
            updateRequest.doc(document);
            bulkRequest.add(updateRequest);
        });
        client.bulk(bulkRequest,RequestOptions.DEFAULT);
    }

    /**
     * 使用RestClient条件查询更新
     * 将使用QueryBuilder中的条件进行查询，并将Document中指定的字段都被更新为对应值
     * @throws IOException
     */
    public void queryUpdateByRestClient() throws IOException {
        //查询条件如果是and关系使用must 如何是or关系使用should
        BoolQueryBuilder boolQueryBuilder =  QueryBuilders.boolQuery()
                .must(QueryBuilders.termQuery(&quot;id&quot;,&quot;1&quot;))
                .should(QueryBuilders.rangeQuery(&quot;doubleVal&quot;).gt(1d));
        Document document = Document.create();
        document.put(&quot;normalText1&quot;,&quot;使用restClient进行条件查询更新&quot;);
        UpdateByQueryRequest request = getUpdateRequst(&quot;demo&quot;, boolQueryBuilder, document);
        client.updateByQuery(request,RequestOptions.DEFAULT);
    }

    /**
     * 构建UpdateByQueryRequest
     * @param index
     * @param query
     * @param document
     * @return
     */
    public UpdateByQueryRequest getUpdateRequst(String index, QueryBuilder query, Document document) {
        UpdateByQueryRequest updateByQueryRequest = new UpdateByQueryRequest(index);
        //设置分片并行
        updateByQueryRequest.setSlices(2);
        //设置版本冲突时继续执行
        updateByQueryRequest.setConflicts(&quot;proceed&quot;);
        //设置更新完成后刷新索引 ps很重要如果不加可能数据不会实时刷新
        updateByQueryRequest.setRefresh(true);
        updateByQueryRequest.setQuery(query);
        StringBuilder script = new StringBuilder();
        Set&lt;String&gt; keys = document.keySet();
        for (String key : keys) {
            String appendValue = &quot;&quot;;
            Object value = document.get(key);
            if (value instanceof Number) {
                appendValue = value.toString();
            } else if (value instanceof String) {
                appendValue = &quot;'&quot; + value.toString() + &quot;'&quot;;
            } else if (value instanceof List){
                appendValue = JSON.toJSONString(value);
            } else {
                appendValue = value.toString();
            }
            script.append(&quot;ctx._source.&quot;).append(key).append(&quot;=&quot;).append(appendValue).append(&quot;;&quot;);
        }
        updateByQueryRequest.setScript(new Script(script.toString()));
        return updateByQueryRequest;
    }
}
</code></pre>
<h4 id="4查询待完善"><strong>4.查询（待完善）</strong></h4>
<pre><code class="language-java">@Service
@RequiredArgsConstructor(onConstructor = @__(@Autowired))
@Slf4j
public class SearchService {

    @Autowired
    private final ElasticsearchRestTemplate template;
    @Autowired
    private final MyEsDemoRepository repository;
    @Autowired
    private final RestHighLevelClient client;
    @Autowired
    private final EsUtil esUtil;

    /**
     * 使用Template进行条件搜索
     * @return
     */
    List&lt;MyEsDemo&gt; searchByTemplate() {
        NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder();
        // 条件筛选，使用QueryBuilders符合需求的查询条件
        builder.withQuery(QueryBuilders.matchQuery(&quot;id&quot;,1));
        builder.withQuery(QueryBuilders.rangeQuery(&quot;doubleVal&quot;).gt(1d));
        builder.withQuery(QueryBuilders.boolQuery().must(QueryBuilders.termQuery(&quot;boolVal&quot;,true)));
        // 排序
        builder.withSorts(SortBuilders.fieldSort(&quot;id&quot;).order(SortOrder.ASC));
        // 分页
        Pageable pageable = PageRequest.of(1, 5);
        builder.withPageable(pageable);
        // 查询结果
        return esUtil.getHitResult(builder, MyEsDemo.class);
    }

    /**
     * 使用Repository进行条件搜索
     * @return
     */
    List&lt;MyEsDemo&gt; searchByRepository(Long id) {
        return repository.findAllByIdEquals(id);
    }

    /**
     * 使用RestClient进行条件搜索
     * @return
     */
    List&lt;MyEsDemo&gt; searchByRestClient() throws IOException {
        SearchScrollRequest request = new SearchScrollRequest();
        client.scroll(request, RequestOptions.DEFAULT);
        return null;
    }
}
</code></pre>
<h3 id="5使用中的问题">5.使用中的问题</h3>
<h4 id="1-分页大小限制">1. 分页大小限制</h4>
<pre><code class="language-shell">org.elasticsearch.ElasticsearchStatusException: Elasticsearch exception [type=search_phase_execution_exception, reason=all shards failed]
 
Caused by: org.elasticsearch.client.ResponseException: method [POST], host [http://**.***.**.***:****], URI [/****/****/_search?typed_keys=true&amp;ignore_unavailable=false&amp;expand_wildcards=open&amp;allow_no_indices=true&amp;search_type=query_then_fetch&amp;batched_reduce_size=512], status line [HTTP/1.1 500 Internal Server Error]
{&quot;error&quot;:{&quot;root_cause&quot;:[{&quot;type&quot;:&quot;query_phase_execution_exception&quot;,&quot;reason&quot;:&quot;Result window is too large, from + size must be less than or equal to: [10000] but was [100001]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level setting.&quot;}],&quot;type&quot;:&quot;search_phase_execution_exception&quot;,&quot;reason&quot;:&quot;all shards failed&quot;,&quot;phase&quot;:&quot;query&quot;,&quot;grouped&quot;:true,&quot;failed_shards&quot;:[{&quot;shard&quot;:0,&quot;index&quot;:&quot;dms-apply-info&quot;,&quot;node&quot;:&quot;IZhu6TvHSh-jm0rinE0f2A&quot;,&quot;reason&quot;:{&quot;type&quot;:&quot;query_phase_execution_exception&quot;,&quot;reason&quot;:&quot;Result window is too large, from + size must be less than or equal to: [10000] but was [100001]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level setting.&quot;}}]},&quot;status&quot;:500}
</code></pre>
<p>从上述报错信息可知，分页时，当from+size &gt; 10000时，es将报错达到数量限制。</p>
<p>通常来说是没有用户会翻页翻到10000条的，但是以防万一，提供如下两种解决方案</p>
<p>**修改 max_result_window **</p>
<p>在 elasticsearch.yml 文件下添加如下配置，然后重启</p>
<pre><code class="language-yaml">max_result_window: 200000000
</code></pre>
<p><strong>采用scroll的方式深度分页</strong></p>
<ol>
<li>创建scroll查询结果的封装对象</li>
</ol>
<pre><code class="language-java">public class EsPageContent&lt;T&gt; {

  
    private SearchScrollHits&lt;T&gt; hit;

    private ElasticsearchRestTemplate template;

    private String indexName;

    private Class&lt;T&gt; c;

    List&lt;String&gt; scrollIds = new ArrayList&lt;&gt;();

    /**
     * 是否有数据
     * @return
     */
    public boolean hasNext() {
        return this.hit.hasSearchHits();
    }

    /**
     * 获取下一个scroll中的数据
     * @return
     */
    public List&lt;T&gt; getNext() {
        String scrollId = this.hit.getScrollId();
        this.scrollIds.add(scrollId);
        List&lt;SearchHit&lt;T&gt;&gt; data = this.hit.getSearchHits();
        List&lt;T&gt; result = data.stream().map(SearchHit::getContent).collect(Collectors.toList());
        // 后续查询
        this.hit = template.searchScrollContinue(scrollId, 60 * 1000, this.c,IndexCoordinates.of(this.indexName));
        return result;
    }

    /**
     * 清除scroll游标
     */
    public void clearScrollIds() {
        this.template.searchScrollClear(scrollIds);
    }

    public void setHit(SearchScrollHits&lt;T&gt; hit) {
        this.hit = hit;
    }

    public void setTemplate(ElasticsearchRestTemplate template) {
        this.template = template;
    }

    public void setIndexName(String indexName) {
        this.indexName = indexName;
    }

    public void setC(Class&lt;T&gt; c) {
        this.c = c;
    }
}
</code></pre>
<ol start="2">
<li>创建EsUtil</li>
</ol>
<pre><code class="language-java">@Component
public class EsUtil {

    @Autowired
    private ElasticsearchRestTemplate template;
    /**
     * 获取es数据分页对象
     * @param query
     * @param c
     * @return
     * @param &lt;T&gt;
     */
    public &lt;T&gt; EsPageContent&lt;T&gt; getPageData(NativeSearchQuery query, Class&lt;T&gt; c) {
        // 设置每页数据量
        String indexName = c.getAnnotation(Document.class).indexName();
        query.setMaxResults(PageSizeConst.ES_PAGE);
        SearchScrollHits&lt;T&gt; searchHits = template.searchScrollStart(60 * 1000, query, c, IndexCoordinates.of(indexName));
        EsPageContent&lt;T&gt; content = new EsPageContent&lt;&gt;();
        content.setIndexName(indexName);
        content.setC(c);
        content.setHit(searchHits);
        content.setTemplate(template);
        return content;
    }

    /**
     * es条件查询
     * @param builder
     * @param c
     * @return
     * @param &lt;T&gt;
     */
    public &lt;T&gt; List&lt;T&gt; listSearchResult(NativeSearchQueryBuilder builder,Class&lt;T&gt; c) {
        List&lt;T&gt; list = new ArrayList&lt;&gt;();
        SearchHits&lt;T&gt; search = template.search(builder.build(), c);
        if (search.getTotalHits() &gt; 0) {
            List&lt;T&gt; result = search.stream().map(SearchHit::getContent).collect(Collectors.toList());
            list.addAll(result);
        }
        return list;
    }
}
</code></pre>
<ol start="3">
<li>使用</li>
</ol>
<pre><code class="language-java">EsPageContent&lt;EsSecurityBasicInfo&gt; content = esUtil.getPageData(nativeSearchQuery, EsSecurityBasicInfo.class);
while (content.hasNext()) {
  List&lt;EsSecurityBasicInfo&gt; list = content.getNext();
  // to do
}
</code></pre>
<h4 id="2-搜索时包含空格报错">2. 搜索时包含空格报错</h4>
<p>使用 Es Repository 进行搜索时，如果传入的字符串中包含空格，会导致es报错，因此可以使用 String 的 replaceAll 和 trim 方法，将所有空格去除</p>
<h4 id="3-text和keyword的使用">3. Text和Keyword的使用</h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://kololantoo.github.io/post/hello-gridea/</id>
        <link href="https://kololantoo.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="http://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>